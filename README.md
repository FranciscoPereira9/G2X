# G2X

![G2X](https://user-images.githubusercontent.com/43917604/177309529-f063d238-de93-4934-9ade-a8bbf4ef22b9.jpg)

As machine learning algorithms infiltrate society, interpretability becomes increasingly important. Graphs to
Explain (G2X), is a model-agnostic interpretability method that combines graphs and other modalities to provide explanations. It learns to explain by maximising mutual information between a selected sub-graph of the input and the response variable of the model being explained. Our proposed method leverages graph neural networks (GNNs) to exploit local and global structures of the data and compute rationales.

The experiments are focused on text data. We compute interpretability metrics that measure the overlap of predicted rationales with human rationales and register
improvements that indicate the ability of G2X to provide more human-like explanations.
